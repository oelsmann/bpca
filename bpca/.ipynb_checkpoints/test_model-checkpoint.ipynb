{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check post seismic deformation module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "               \n",
    "class discotimes_model(pm.model.Model):\n",
    "    # 1) override init\n",
    "    \n",
    "    \"\"\"model for changepoint detection (discontinuities and trend changes)\n",
    "    type pm.model.Model\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, observed=None,name='', model=None,change_trend=False,n_changepoints=5,offsets_std=1,p_=0.1,\n",
    "                      sigma_noise=1.,trend_inc_sigma=0.01,annual_cycle=False,change_offsets=True,\n",
    "                 estimate_offset_sigma=False,estimate_trend_inc_sigma=False,post_seismic=False,\n",
    "                 AR1=False,distribute_offsets=False,robust_reg=False,initial_values={},**kwargs):\n",
    "        \n",
    "        \"\"\"Requires parameters as defined in model_settings\n",
    "        \n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        \n",
    "        observed : discotimes.observed\n",
    "            observed object\n",
    "        name : str\n",
    "            Name of the data/model\n",
    "        change_trend : bool\n",
    "            Turn on/off changing trend fits\n",
    "        n_changepoints : int\n",
    "            Maximum allowed number of change points\n",
    "        offsets_std : float\n",
    "            prior: offsets std\n",
    "        p_ : 0.1,\n",
    "            prior: Bernoulli's initial p (probability of a change point 0.1 ==10%)\n",
    "        sigma_noise : float\n",
    "            prior: white-noise sigma       \n",
    "        trend_inc_sigma : float\n",
    "            prior: trend-increments hyperparameter sigma       \n",
    "        annual_cycle : bool\n",
    "            Turn on/off annual cycle estimation       \n",
    "        change_offsets : bool\n",
    "            Turn on/off estimating discontinuities (named here offsets)\n",
    "        estimate_offset_sigma : bool\n",
    "            Turn on/off estimating hyperparameter offset sigma        \n",
    "        estimate_trend_inc_sigma : bool\n",
    "            Turn on/off estimating hyperparameter trend-inc. sigma   \n",
    "        post_seismic : bool\n",
    "            Turn on/off post-seismic module ! to be implemented\n",
    "        AR1 : bool\n",
    "            Turn on/off AR1 model, if false, only white noise is estimated\n",
    "        distribute_offsets : bool\n",
    "            Turn on/off equally distribute offsets in the beginning        \n",
    "        robust_reg : bool\n",
    "            Turn on/off ! future implementation to deal with strong outliers       \n",
    "        initial_values : dict\n",
    "            dictionary of initial conditions e.g. \n",
    "            {'n_changepoints':n_changepoints,'p_':p_,'positions':positions,'offsets':offsets}\n",
    "        \n",
    "        \"\"\"\n",
    "        super().__init__(name,model)\n",
    "\n",
    "        \n",
    "        x=observed.x\n",
    "        y=observed.y\n",
    "            \n",
    "        xmin=np.min(x)\n",
    "        xmax=np.max(x)\n",
    "        \n",
    "        \n",
    "        X_mat=observed.X_mat\n",
    "        \n",
    "        if 'offsets' in initial_values:\n",
    "            # integrate pre-defined offsets\n",
    "            initialize=True\n",
    "            print('manually initialize with: ')\n",
    "            print(initial_values)\n",
    "            estimate_offset_sigma=False\n",
    "            offsets_mu=initial_values['offsets']\n",
    "            p_=initial_values['p_']\n",
    "            start = {'offsets': initial_values['offsets'], 'positions': initial_values['positions']}\n",
    "\n",
    "        else:\n",
    "            offsets_mu=0\n",
    "            start={}\n",
    "\n",
    "        # Priors for model parameters\n",
    "        offset = pm.Normal('offset', mu=0, sigma=1)\n",
    "        trend = pm.Normal('trend', mu=0, sigma=1) \n",
    "        sigma = pm.HalfNormal('sigma', sigma=sigma_noise)   \n",
    "        act_number = pm.Bernoulli('act_number', p = p_, shape=n_changepoints)\n",
    "\n",
    "        if not change_offsets:\n",
    "            mult_offsets=0.\n",
    "        else:\n",
    "            mult_offsets=1. \n",
    "\n",
    "        if estimate_offset_sigma: # estimate one distribution for multiple offsets\n",
    "            offset_sigma = pm.HalfNormal('offset_sigma', sigma=offsets_std)   \n",
    "            offsets = pm.Normal('offsets', mu=offsets_mu, sigma=offset_sigma,\n",
    "                                shape=n_changepoints)*mult_offsets   \n",
    "            \n",
    "        else: # estimate multiple distributions for multiple offsets\n",
    "            offsets = pm.Normal('offsets', mu=offsets_mu, sigma=offsets_std,\n",
    "                                shape=n_changepoints)*mult_offsets  \n",
    "\n",
    "        mult=pm.Deterministic('mult', (act_number> 0.5)*1) # array with 1,0 defining changep =True/False\n",
    "        offsets=offsets*mult\n",
    "        if distribute_offsets:\n",
    "            # equally distributed offset initial positions\n",
    "            mup=np.linspace(xmin,xmax,n_changepoints)\n",
    "            mu_pos=pm.Uniform('mu_pos',mup, lower=xmin, upper=xmax, shape=n_changepoints) \n",
    "        else: \n",
    "            # randomly distributed offsets\n",
    "            mu_pos=pm.Uniform('mu_pos', lower=xmin, upper=xmax, shape=n_changepoints) \n",
    "\n",
    "        s = pm.Normal('positions',  mu=mu_pos, sigma=5, shape=n_changepoints)\n",
    "\n",
    "        A = (x[:, None] >= s) * 1\n",
    "        offset_change = elem_matrix_vector_product(A, offsets)\n",
    "\n",
    "        if change_trend:\n",
    "            if estimate_trend_inc_sigma:\n",
    "                # estimate one hyperparameter distribution from which trend increments can stem from\n",
    "                trend_inc_sigma_est = pm.HalfNormal('trend_inc_sigma_est', sigma=trend_inc_sigma)  \n",
    "                trend_inc = pm.Normal('trend_inc', mu=0, sigma=trend_inc_sigma_est,shape=n_changepoints)\n",
    "            else:\n",
    "                # no hyperparameter distribution estimation\n",
    "                trend_inc = pm.Normal('trend_inc', mu=0, sigma=trend_inc_sigma,shape=n_changepoints)\n",
    "            trend_inc=trend_inc*mult\n",
    "            gamma = -s* trend_inc\n",
    "\n",
    "            trend_inc=elem_matrix_vector_product(A, trend_inc)\n",
    "            trend=trend+trend_inc\n",
    "            A_gamma=elem_matrix_vector_product(A, gamma)\n",
    "            offset_change=offset_change+A_gamma\n",
    "        if post_seismic:\n",
    "            # !!! not implemented yet !!!\n",
    "            # add exponential term to every trend section\n",
    "            \n",
    "            \n",
    "            c_constant=pm.Normal('c_constant', mu=0, sigma=2,shape=n_changepoints)\n",
    "            etau=pm.HalfNormal('etau', sigma=3,shape=n_changepoints)  \n",
    "            \n",
    "            \n",
    "            \n",
    "            t_vec=(A*x[:,None])-s\n",
    "            inside_function=((t_vec-t_vec*[t_vec<0]).squeeze()/etau)              \n",
    "            post_seismic=sum(c_constant*(1-np.exp(-((t_vec-t_vec*[t_vec<0]).squeeze()/etau)))*mult,axis=1)\n",
    "            offset_change=offset_change+post_seismic \n",
    "        if annual_cycle:\n",
    "            m_coeffs=pm.Normal('m_coeffs', mu=0, sigma=1,shape=12)\n",
    "            annual=pm.Deterministic(\"annual\", elem_matrix_vector_product(X_mat,m_coeffs)) \n",
    "            mu = pm.Deterministic(\"mu\", offset_change + trend*x + offset + annual)   \n",
    "        else:\n",
    "            mu = pm.Deterministic(\"mu\", offset_change + trend*x + offset)            \n",
    "        if robust_reg:\n",
    "            # !!! not implemented yet !!!\n",
    "            sigma_s = pm.HalfNormal('sigma_s', sigma=sigma_noise) \n",
    "            nu = pm.InverseGamma(\"nu\", alpha=1, beta=1)\n",
    "            mu = pm.StudentT(\"mu\", mu=offset_change + trend*x + offset,\n",
    "                             sigma=sigma_s, nu=nu)\n",
    "      \n",
    "        else:\n",
    "            if AR1: # first order autoregressive ...\n",
    "                beta = pm.HalfNormal('beta', sigma=0.4)\n",
    "                likelihood = pm.AR('AR1_coeff', beta, sigma=sigma, observed=y-mu) \n",
    "            else:    \n",
    "                Y_obs = pm.Normal('Y_obs', mu=mu, sigma=sigma, observed=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-086197ab6253>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdiscofit\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Julius/Scripts/discotimes/discotimes/discofit.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdiscotimes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdiscotimes\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmodel_settings\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Julius/Scripts/discotimes/discotimes/discotimes.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "from discofit import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tests.custom_settings import external_settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from discotimes import discotimes as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    specs={}\n",
    "    specs['n_changepoints']=5\n",
    "    specs['offsets_opt']='normal'\n",
    "    specs['offsets_std']=20.\n",
    "    specs['add_to_num'] = 0.        \n",
    "    specs['model']=None\n",
    "    specs['name']=''\n",
    "    specs['change_trend']=True\n",
    "    specs['change_offsets']=True\n",
    "    specs['n_samples']=8000\n",
    "    specs['trend_inc_sigma']=1.\n",
    "    specs['target_accept']=0.9\n",
    "    specs['add_to_num']=0\n",
    "    specs['post_seismic']=False\n",
    "    specs['estimate_offset_sigma']=True\n",
    "    specs['estimate_trend_inc_sigma']=True  #\n",
    "    specs['annual_cycle']=True    \n",
    "    specs['AR1']=True\n",
    "    specs['p_']=0.1\n",
    "    if 'model_settings' in external_settings:\n",
    "        for item in external_settings['model_settings']:\n",
    "            specs[item]=external_settings['model_settings'][item]  \n",
    "    return specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{} == {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ymod(self,chain,n_changepoints=5,denormalize=True,change_trend=True,\n",
    "         trend_inc=None,change_offsets=True,post_seismic=False,annual_cycle=False,**kwargs):\n",
    "    \n",
    "    \"\"\"convert model samples to dictionary of parameters\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    chain : int\n",
    "        number of chain to look at\n",
    "    n_changepoints : int \n",
    "        maximum allowed number of changepoints\n",
    "    denormalize : bool\n",
    "        re-scale data\n",
    "    \n",
    "    ... other model settings parameters\n",
    "    \n",
    "    Returns\n",
    "    --------\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    data=self.trace['mean'].sel(chain=[chain]).posterior.squeeze(dim='chain')\n",
    "    data_std=self.trace['std'].sel(chain=[chain]).posterior.squeeze(dim='chain')        \n",
    "    mult = ((data['mult']> 0.5)*1).values # 1,0 vector of changepoints\n",
    "    num = np.sum(mult)\n",
    "\n",
    "    offsets=data.offsets.values*mult\n",
    "    offset=data.offset\n",
    "    x=self.obs.x\n",
    "\n",
    "    if not change_offsets:\n",
    "        offsets=offsets*0\n",
    "    positions = data.positions.values\n",
    "    A = (x[:, None] >= positions) * 1\n",
    "    offset_change = det_dot(A, offsets)\n",
    "    trend=data.trend.values\n",
    "    trend_err=data_std.trend.values\n",
    "    trend_v=trend\n",
    "    trend_err_v=trend_err\n",
    "    if change_trend:      \n",
    "        trend_inc=data.trend_inc.values*mult\n",
    "        trend_inc_err=data_std.trend_inc.values*mult \n",
    "\n",
    "        if trend_independent: # no autocorrelation in trend itself\n",
    "            trend_v=copy.deepcopy(np.append(trend_v, (trend_inc+trend_v)*mult))\n",
    "            trend_err_v=copy.deepcopy(np.append(trend_err_v, trend_inc_err))\n",
    "            gamma=-positions* trend_inc+np.roll(np.diff(positions,append=s[-1])*trend_inc,1).cumsum()\n",
    "            A = (x[:, None] >= s) * 1\n",
    "            A_alt=np.diff(A,axis=1,append=0)*-1\n",
    "            trend_inc=det_dot(A_alt, trend_inc)\n",
    "            A_gamma=det_dot(A_alt, gamma)\n",
    "            trend=trend+trend_inc\n",
    "        else:\n",
    "            trend_v=copy.deepcopy(np.append(trend_v, (trend_inc+trend_v)*mult))\n",
    "            trend_err_v=copy.deepcopy(np.append(trend_err_v, trend_inc_err))\n",
    "\n",
    "            gamma = -positions * trend_inc\n",
    "            trend_inc=det_dot(A, trend_inc)\n",
    "            trend=trend+trend_inc\n",
    "            A_gamma=det_dot(A, gamma)\n",
    "\n",
    "        offset_change=offset_change+A_gamma\n",
    "        trend_v_sorted=pd.DataFrame(trend).drop_duplicates()\n",
    "        start_pos=self.obs.series_clean.index[trend_v_sorted.index.values]\n",
    "        end_pos=self.obs.series_clean.index[np.roll(trend_v_sorted.index.values-1,shift=-1)]\n",
    "        diff=end_pos-start_pos\n",
    "\n",
    "        # trend uncertainty and offsets\n",
    "        trend_inc_err=data_std.trend_inc.values*mult \n",
    "        ff = pd.DataFrame(np.vstack([positions*mult,trend_inc_err*mult,offsets*mult]).T,columns=['pos','trend_inc_err','offsets'])\n",
    "        x=self.obs.x\n",
    "        args_m=[]\n",
    "        for pos in positions:\n",
    "            args_m.append(np.argmin(abs(x-pos)))\n",
    "        ff['real_p']=self.obs.series_clean.index[args_m]\n",
    "        ff=ff[ff['pos']!=0].sort_values(by='pos')\n",
    "        ff2=copy.deepcopy(ff)\n",
    "        if len(ff)==0:\n",
    "            full_err = pd.DataFrame(np.vstack([0,trend_err,offset,start_pos[0]]).T,columns=['pos','trend_inc_err','offsets','real_p'])\n",
    "\n",
    "        else:\n",
    "            ff2.iloc[0]=np.vstack([0,trend_err,offset,start_pos[0]]).flatten()\n",
    "            full_err=pd.concat([ff,ff2.iloc[0:1]]).sort_values(by='pos')\n",
    "\n",
    "\n",
    "\n",
    "    if post_seismic:\n",
    "        new=(A*x[:,None])-s\n",
    "        #new[new<0]=0\n",
    "        post=np.nansum(data.c_constant.values*(1-np.exp(-((new-new*[new<0]).squeeze()/data.etau.values)))*mult,axis=1)\n",
    "        y_mod=offset_change + trend*x + data.offset.values +post\n",
    "    else:\n",
    "        post=np.nan\n",
    "        y_mod=offset_change + trend*x + data.offset.values \n",
    "    if annual_cycle:\n",
    "        annual=data.annual.values\n",
    "        y_mod=y_mod+annual\n",
    "\n",
    "    if self.specs['model_type'] == 'exp_independent_cp' and change_trend and change_offsets:\n",
    "        trend_v =np.append(trend_v[0],trend_v[1:][mult==1])\n",
    "        positions = positions[mult==1]\n",
    "        trend_err_v=np.append(trend_err_v[0],trend_err_v[1:][mult==1])\n",
    "        positions_v=self.positions_to_date(positions)\n",
    "\n",
    "    elif self.specs['model_type'] == 'exp_independent_cp' and not change_trend and not change_offsets:\n",
    "        trend_v =np.asarray(trend)\n",
    "        trend_err_v=np.asarray(trend_err_v)\n",
    "        positions_v=self.obs.series_clean.index[0]  \n",
    "        mult=mult*0\n",
    "        num=0\n",
    "        trend_v_sorted=pd.DataFrame([trend])\n",
    "        start_pos=self.obs.series_clean.index[0]\n",
    "        end_pos=self.obs.series_clean.index[-1]\n",
    "        diff=end_pos-start_pos        \n",
    "        full_err = pd.DataFrame(np.vstack([0,trend_err,offset,start_pos]).T,columns=['pos','trend_inc_err','offsets','real_p'])\n",
    "\n",
    "    else:\n",
    "        positions_v=self.positions_to_date(positions*mult)\n",
    "\n",
    "    if denormalize:\n",
    "        return {'ymod':y_mod*self.obs.std,'trend':trend*self.obs.std,\n",
    "                'post':post*self.obs.std,'offset_change':(offset_change+data.offset.values)*self.obs.std,\n",
    "               'trend_v':trend_v*self.obs.std,'trend_err_v':trend_err_v*self.obs.std,'act_num':np.round(num),\n",
    "                'positions_v':positions_v,'mult':mult,'trend_v_sorted':trend_v_sorted.values.flatten()*self.obs.std,\n",
    "                'start_pos':start_pos,'end_pos':end_pos,'diff':diff,\n",
    "                'trend_un':full_err['trend_inc_err'].values*self.obs.std,\n",
    "                'offsets':full_err['offsets'].values*self.obs.std}          \n",
    "    else:\n",
    "        return {'ymod':y_mod,'trend':trend,'post':post,'offset_change':offset_change+data.offset.values}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib.util\n",
    "spec = importlib.util.spec_from_file_location(\"custom_settings\", 'tests/custom_settings.py')\n",
    "custom_settings = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(custom_settings)\n",
    "#foo.MyClass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'run_settings': {'n_samples': 16000,\n",
       "  'tune': 2000,\n",
       "  'cores': 8,\n",
       "  'nuts': {'target_accept': 0.9},\n",
       "  'return_inferencedata': True,\n",
       "  'compress': True},\n",
       " 'initial_run_settings': {'detection_threshold': 25},\n",
       " 'model_settings': {'n_changepoints': 10, 'change_trend': False}}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_settings.custom_settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'run_settings': {'n_samples': 16000,\n",
       "  'tune': 2000,\n",
       "  'cores': 8,\n",
       "  'nuts': {'target_accept': 0.9},\n",
       "  'return_inferencedata': True,\n",
       "  'compress': True},\n",
       " 'initial_run_settings': {'detection_threshold': 25},\n",
       " 'model_settings': {'n_changepoints': 10, 'change_trend': False}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "external_settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "None is not None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
